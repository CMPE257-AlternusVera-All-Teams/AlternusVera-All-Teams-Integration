# -*- coding: utf-8 -*-
"""Mayuri-alternus_vera_GO_ML_Factors_Integration_Sprint4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qiMwgUd7kTmHSxuSaD4mfG_n3q9RXK4N

# GO-ML Team
## Team members and factors

- Praveen Kumar Thakur - News Coverage
- Amit Vijapure - Stance Detection
- Mayuri Bhise - ClickBait
- Dhwani Sanghvi -  Writing Style

## Connect to Google Drive to read datasets and pickled models
"""
import pickle
from sklearn.feature_extraction.text import TfidfVectorizer
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import re
import numpy as np
import pandas as pd

"""## Import Libraries"""

nltk.download('punkt')
nltk.download('stopwords')


"""## Stance Detection"""


class StanceDetection():
    def __init__(self, filenameModel, filenamePkl):
        self.clf = pickle.load(open(filenameModel, 'rb'))
        self.vector: TfidfVectorizer = pickle.load(
            open(filenamePkl, 'rb'))

    def __predict(self, text):
        a = self.vector.transform([text])
        predicted = self.clf.predict(a)
        predicedProb = self.clf.predict_proba(
            a)[0][0] + self.clf.predict_proba(a)[0][1]
        return predicedProb

    def getStanceDetectionScore(self, text):
        text = re.sub('[^a-zA-Z ]', '', text).lower()
        text = ' '.join(
            [w for w in text.split() if w not in stopwords.words('english')])
        return self.__predict(text)


"""## Clickbait Detection"""


class Clickbait():

    def __init__(self, filenameModel, filenamePkl):
        self.clf = pickle.load(open(filenameModel, 'rb'))
        self.vector: TfidfVectorizer = pickle.load(
            open(filenamePkl, 'rb'))

    def __predict(self, text):
        a = self.vector.transform([text])
        predicted = self.clf.predict(a)
        predicedProb = self.clf.predict_proba(
            a)[0][0] + self.clf.predict_proba(a)[0][1]
        return predicedProb

    def getClickbaitScore(self, text):
        text = re.sub('[^a-zA-Z ]', '', text).lower()
        text = ' '.join(
            [w for w in text.split() if w not in stopwords.words('english')])
        return self.__predict(text)


"""## News Coverage"""


class NewsCoverage():

    def __init__(self, filenameModel, filenamePkl):
        self.clf = pickle.load(open(filenameModel, 'rb'))
        self.vector: TfidfVectorizer = pickle.load(
            open(filenamePkl, 'rb'))

    def __predict(self, text):
        a = self.vector.transform([text])
        #predicted = self.clf.predict(a)
        predicedProb = self.clf.predict_proba(
            a)[0][0] + self.clf.predict_proba(a)[0][1]
        return predicedProb

    def getNewsCoverageScore(self, text):
        text = re.sub('[^a-zA-Z ]', '', text).lower()
        text = ' '.join(
            [w for w in text.split() if w not in stopwords.words('english')])
        return self.__predict(text)


"""## Writing Style"""


class WritingStyle():

    def __init__(self, filenamePkl):
        self.clf = pickle.load(open(filenamePkl, 'rb'))

    def __predict(self, text):
        predicted = self.clf.predict([text])
        predicedProb = self.clf.predict_proba([text])[:, 1]
        return bool(predicted), float(predicedProb)

    # return between 0 and 1, being 0 = True,  1 = Fake
    def WritingStyleScore(self, text):
        binaryValue, probValue = self.__predict(text)
        return (1 - float(probValue))

# def isFakeNews(text, headline="", numAuthors = 0, source = "", party =""):
#     accur = [0.87, 0.70, 0.82, 0.85] # using the (normalized) accuracy as weigths
